import streamlit as st
import torch
import os
import zipfile
import gdown
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ---------------- CONFIG ----------------
MODEL_DIR = "model_runtime"
ZIP_PATH = "model_runtime.zip"
GDRIVE_ZIP_URL = "https://drive.google.com/uc?id=1cyjqbVRAhOAogoUWY1_zhby9uy9VdSPR"

LABELS = {
    0: "‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢",
    1: "‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"
}

# optional heuristic list (NOT decision)
PROFANITY_HINTS = [
    "‡∏≠‡∏µ", "‡πÑ‡∏≠‡πâ", "‡πÄ‡∏´‡∏µ‡πâ‡∏¢", "‡∏Ñ‡∏ß‡∏≤‡∏¢", "‡∏™‡∏±‡∏ï‡∏ß‡πå", "‡∏î‡∏≠‡∏Å"
]

# ---------------- LOAD MODEL ----------------
@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_DIR):
        gdown.download(GDRIVE_ZIP_URL, ZIP_PATH, quiet=False)
        with zipfile.ZipFile(ZIP_PATH, "r") as zip_ref:
            zip_ref.extractall(MODEL_DIR)

    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_DIR,
        use_fast=False
    )
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
    model.eval()
    return tokenizer, model


tokenizer, model = load_model()

# ---------------- UI ----------------
st.title("SafeText üáπüá≠")
st.caption("Thai Legal Risk Analyzer")

text = st.text_area("‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
context = st.selectbox(
    "‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£",
    ["public_post", "private_dm", "email", "letter"]
)

if st.button("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå") and text.strip():

    # ---------- BOX 1: LANGUAGE NOTE ----------
    found_hints = [w for w in PROFANITY_HINTS if w in text]

    st.subheader("üó£Ô∏è ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ñ‡πâ‡∏≠‡∏¢‡∏Ñ‡∏≥")
    if found_hints:
        st.warning(
            "‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ñ‡πâ‡∏≠‡∏¢‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° "
            "(‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢)"
        )
    else:
        st.success("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ñ‡πâ‡∏≠‡∏¢‡∏Ñ‡∏≥‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô")

    # ---------- BOX 2: AI LEGAL RISK ----------
    input_text = f"[CONTEXT] {context} [TEXT] {text}"

    inputs = tokenizer(
        input_text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=256
    )

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)[0]
        pred = probs.argmax().item()

    st.subheader("‚öñÔ∏è ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
    st.info(f"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: **{LABELS[pred]}**")

    st.write("‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:")
    for i, p in enumerate(probs):
        st.write(f"- {LABELS[i]}: {p:.2%}")
